# 6장 최소제곱법을 이용한 가설검정


```python
## https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html#scipy.stats.t
from scipy.stats import t
```


```python
t.ppf(.975, 23)
```



```output
2.0686576104190406
```



```python
t.ppf(.95, 23)
```



```output
1.713871527747047
```


## Housing


```python
import numpy as np
import pandas as pd
import statsmodels.formula.api as smf

Housing = pd.read_csv('csv/Ecdat/Housing.csv')
ols = smf.ols('np.log(price)~np.log(lotsize)', data=Housing).fit()
print(ols.summary())
```

```output
                            OLS Regression Results                            
==============================================================================
Dep. Variable:          np.log(price)   R-squared:                       0.336
Model:                            OLS   Adj. R-squared:                  0.335
Method:                 Least Squares   F-statistic:                     275.8
Date:                Wed, 11 Feb 2026   Prob (F-statistic):           2.14e-50
Time:                        02:26:17   Log-Likelihood:                -122.36
No. Observations:                 546   AIC:                             248.7
Df Residuals:                     544   BIC:                             257.3
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
Intercept           6.4685      0.277     23.374      0.000       5.925       7.012
np.log(lotsize)     0.5422      0.033     16.606      0.000       0.478       0.606
==============================================================================
Omnibus:                        0.255   Durbin-Watson:                   1.086
Prob(Omnibus):                  0.880   Jarque-Bera (JB):                0.333
Skew:                          -0.045   Prob(JB):                        0.847
Kurtosis:                       2.920   Cond. No.                         183.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```

```python
from scipy.stats import t

t.ppf(.995, 544)
```

```output
2.5848970040670145
```

## 예제 6.1 가구주 나이와 통신비 지출 비중


```python
import pandas as pd
from statsmodels.api import OLS

Hcons = pd.read_csv('csv/loedata/Hcons.csv')
print(Hcons.describe())
```

```output
               age         comm          rec
count  6723.000000  6723.000000  6723.000000
mean     45.860033     6.841078     5.162530
std       8.237180     3.925046     4.836962
min      30.000000     0.000000     0.000000
25%      39.000000     4.261053     2.253281
50%      46.000000     6.031846     3.856771
75%      53.000000     8.440650     6.514518
max      60.000000    37.129649    72.807483
```


```python
ols = smf.ols('comm~age', data=Hcons).fit()
print(ols.summary())
```

```output
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   comm   R-squared:                       0.001
Model:                            OLS   Adj. R-squared:                  0.001
Method:                 Least Squares   F-statistic:                     4.522
Date:                Wed, 11 Feb 2026   Prob (F-statistic):             0.0335
Time:                        02:28:01   Log-Likelihood:                -18730.
No. Observations:                6723   AIC:                         3.746e+04
Df Residuals:                    6721   BIC:                         3.748e+04
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      6.2744      0.271     23.176      0.000       5.744       6.805
age            0.0124      0.006      2.127      0.033       0.001       0.024
==============================================================================
Omnibus:                     2757.039   Durbin-Watson:                   1.844
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15710.710
Skew:                           1.887   Prob(JB):                         0.00
Kurtosis:                       9.468   Cond. No.                         264.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```


## p값


```python
from scipy.stats import t

2*t.cdf(-1.54,48)
```

```output
0.13012747345659167
```



```python
2*(1-t.cdf(1.54,48))
```

```output
0.1301274734565918
```

## t(544) 분포의 5% 임계값


```python
t.ppf(.975, 544)
```

```output
1.9643343306673329
```


## 예제 6.2 고령자의 배우자 존재 여부와 삶의 만족도


```python
import pandas as pd
Klosa = pd.read_csv('csv/loedata/Klosa.csv')
# Subsetting
Klosa1 = Klosa[(Klosa['working']==0) & (Klosa['age']>=65)]

import statsmodels.formula.api as smf
fm = 'satisfy5~married'
print(smf.ols(fm, data=Klosa1).fit().summary())
```

```output
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               satisfy5   R-squared:                       0.026
Model:                            OLS   Adj. R-squared:                  0.025
Method:                 Least Squares   F-statistic:                     28.49
Date:                Wed, 11 Feb 2026   Prob (F-statistic):           1.15e-07
Time:                        02:29:34   Log-Likelihood:                -4641.8
No. Observations:                1060   AIC:                             9288.
Df Residuals:                    1058   BIC:                             9297.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     51.5534      0.851     60.562      0.000      49.883      53.224
married        6.3365      1.187      5.337      0.000       4.007       8.666
==============================================================================
Omnibus:                       27.276   Durbin-Watson:                   1.739
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.010
Skew:                          -0.402   Prob(JB):                     5.02e-07
Kurtosis:                       2.904   Cond. No.                         2.65
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```


```python
import numpy as np
np.std(Klosa.satisfy5)
```



```output
18.522274892616505
```



```python
print(smf.ols(fm, data=Klosa1[Klosa1.hlth3>=0]).fit().summary())
```

```output
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               satisfy5   R-squared:                       0.002
Model:                            OLS   Adj. R-squared:                 -0.001
Method:                 Least Squares   F-statistic:                    0.5670
Date:                Wed, 11 Feb 2026   Prob (F-statistic):              0.452
Time:                        02:30:23   Log-Likelihood:                -1250.9
No. Observations:                 300   AIC:                             2506.
Df Residuals:                     298   BIC:                             2513.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     62.1186      1.446     42.960      0.000      59.273      64.964
married        1.3978      1.856      0.753      0.452      -2.256       5.051
==============================================================================
Omnibus:                       11.384   Durbin-Watson:                   1.656
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.106
Skew:                          -0.484   Prob(JB):                      0.00235
Kurtosis:                       2.824   Cond. No.                         2.95
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```



```python
print(smf.ols(fm, data=Klosa1[Klosa1.hlth3<0]).fit().summary())
```

```output
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               satisfy5   R-squared:                       0.028
Model:                            OLS   Adj. R-squared:                  0.026
Method:                 Least Squares   F-statistic:                     21.54
Date:                Wed, 11 Feb 2026   Prob (F-statistic):           4.08e-06
Time:                        02:31:11   Log-Likelihood:                -3344.5
No. Observations:                 760   AIC:                             6693.
Df Residuals:                     758   BIC:                             6702.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     48.4131      0.991     48.849      0.000      46.468      50.359
married        6.6558      1.434      4.641      0.000       3.841       9.471
==============================================================================
Omnibus:                       11.637   Durbin-Watson:                   1.738
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               11.918
Skew:                          -0.294   Prob(JB):                      0.00258
Kurtosis:                       2.828   Cond. No.                         2.57
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```



## 신뢰구간


```python
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf

Housing = pd.read_csv('csv/Ecdat/Housing.csv')
ols = smf.ols('np.log(price)~np.log(lotsize)', data=Housing).fit()

## https://stackoverflow.com/questions/44302099/python-statsmodels-ols-confidence-interval
## https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.conf_int.html
print(ols.conf_int(alpha=.05))
```

```output
                        0         1
Intercept        5.924920  7.012143
np.log(lotsize)  0.478043  0.606315
```



```python
print(ols.conf_int(alpha=.01))
```

```output
                        0         1
Intercept        5.753185  7.183879
np.log(lotsize)  0.457782  0.626576
```



## 예제 6.3 2012년 한국 상장기업 급여


```python
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf

Ksalary = pd.read_csv('csv/loedata/Ksalary.csv')
Ksalary1 = Ksalary[(Ksalary.kospi==1) & (Ksalary.sector=='ElecElectron')]
ols = smf.ols('np.log(avgsal)~np.log(sales/emp)', data=Ksalary1).fit()
print(ols.summary())
```

```output
                            OLS Regression Results                            
==============================================================================
Dep. Variable:         np.log(avgsal)   R-squared:                       0.101
Model:                            OLS   Adj. R-squared:                  0.084
Method:                 Least Squares   F-statistic:                     6.072
Date:                Wed, 11 Feb 2026   Prob (F-statistic):             0.0169
Time:                        02:33:14   Log-Likelihood:               -0.95089
No. Observations:                  56   AIC:                             5.902
Df Residuals:                      54   BIC:                             9.952
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
=======================================================================================
                          coef    std err          t      P>|t|      [0.025      0.975]
---------------------------------------------------------------------------------------
Intercept               3.8047      0.046     82.889      0.000       3.713       3.897
np.log(sales / emp)     0.1225      0.050      2.464      0.017       0.023       0.222
==============================================================================
Omnibus:                        0.191   Durbin-Watson:                   0.216
Prob(Omnibus):                  0.909   Jarque-Bera (JB):                0.337
Skew:                           0.119   Prob(JB):                        0.845
Kurtosis:                       2.704   Cond. No.                         2.32
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```



```python
print(ols.conf_int(.01))
```

```output
                            0         1
Intercept            3.682129  3.927238
np.log(sales / emp) -0.010231  0.255249
```



```python
print(ols.conf_int(.05))
```

```output
                            0         1
Intercept            3.712658  3.896709
np.log(sales / emp)  0.022836  0.222183
```



## 예제 6.4 주택가격


```python
Housing['unitprice'] = [pi/li for pi,li in zip(Housing.price, Housing.lotsize)]
ols = smf.ols('np.log(unitprice)~np.log(lotsize)', data=Housing).fit()
ols.summary()
```

<style>
.simpletable th, .simpletable td { padding: 0 8px 0 8px; }
.simpletable th { font-weight: bold }
</style>


<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>np.log(unitprice)</td> <th>  R-squared:         </th> <td>  0.2655</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>  0.2641</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   196.6</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 23 Jun 2024</td>  <th>  Prob (F-statistic):</th>  <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>14:11:56</td>      <th>  Log-Likelihood:    </th> <td> -122.36</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   546</td>       <th>  AIC:               </th> <td>   248.7</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   544</td>       <th>  BIC:               </th> <td>   257.3</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>       <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>            <th>coef</th>      <th>std err</th>      <th>t</th>      <th>P>|t|</th>   <th>[0.025</th>     <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>       <td>   6.46853</td> <td>   0.27674</td> <td>    23.37</td> <td> 0.000</td> <td>   5.92492</td> <td>   7.01214</td>
</tr>
<tr>
  <th>np.log(lotsize)</th> <td>  -0.45782</td> <td>   0.03265</td> <td>   -14.02</td> <td> 0.000</td> <td>  -0.52196</td> <td>  -0.39369</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.255</td> <th>  Durbin-Watson:     </th> <td>   1.086</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.880</td> <th>  Jarque-Bera (JB):  </th> <td>   0.333</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.045</td> <th>  Prob(JB):          </th> <td>   0.847</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.920</td> <th>  Cond. No.          </th> <td>    183.</td>
</tr>
</table><br/><br/>Notes:<br/>1. Standard Errors assume that the covariance matrix of the errors is correctly specified.



## 예제 6.5 담배소비의 가격탄력성


```python
import pandas as pd
import statsmodels.formula.api as smf

data = pd.read_csv('csv/AER/CigarettesB.csv')
smf.ols('packs~price', data=data).fit().summary()
```

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>packs</td>      <th>  R-squared:         </th> <td>  0.2913</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  0.2752</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   18.08</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 23 Jun 2024</td> <th>  Prob (F-statistic):</th>  <td>0.0001</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>14:12:16</td>     <th>  Log-Likelihood:    </th> <td>  19.195</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    46</td>      <th>  AIC:               </th> <td>  -34.39</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>  -30.73</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>      <th>std err</th>      <th>t</th>      <th>P>|t|</th>   <th>[0.025</th>     <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   5.09411</td> <td>   0.06270</td> <td>    81.25</td> <td> 0.000</td> <td>   4.96775</td> <td>   5.22047</td>
</tr>
<tr>
  <th>price</th>     <td>  -1.19832</td> <td>   0.28179</td> <td>    -4.25</td> <td> 0.000</td> <td>  -1.76622</td> <td>  -0.63041</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 1.860</td> <th>  Durbin-Watson:     </th> <td>   2.307</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.395</td> <th>  Jarque-Bera (JB):  </th> <td>   1.209</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.389</td> <th>  Prob(JB):          </th> <td>   0.546</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.164</td> <th>  Cond. No.          </th> <td>    12.2</td>
</tr>
</table><br/><br/>Notes:<br/>1. Standard Errors assume that the covariance matrix of the errors is correctly specified.




```python
smf.ols('I(packs+price)~price', data=data).fit().summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>I(packs + price)</td> <th>  R-squared:         </th> <td>  0.0111</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td> -0.0113</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.4953</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 23 Jun 2024</td> <th>  Prob (F-statistic):</th>  <td>0.4853</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>14:12:25</td>     <th>  Log-Likelihood:    </th> <td>  19.195</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    46</td>      <th>  AIC:               </th> <td>  -34.39</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>  -30.73</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>      <th>std err</th>      <th>t</th>      <th>P>|t|</th>   <th>[0.025</th>     <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   5.09411</td> <td>   0.06270</td> <td>    81.25</td> <td> 0.000</td> <td>   4.96775</td> <td>   5.22047</td>
</tr>
<tr>
  <th>price</th>     <td>  -0.19832</td> <td>   0.28179</td> <td>    -0.70</td> <td> 0.485</td> <td>  -0.76622</td> <td>   0.36959</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 1.860</td> <th>  Durbin-Watson:     </th> <td>   2.307</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.395</td> <th>  Jarque-Bera (JB):  </th> <td>   1.209</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.389</td> <th>  Prob(JB):          </th> <td>   0.546</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.164</td> <th>  Cond. No.          </th> <td>    12.2</td>
</tr>
</table><br/><br/>Notes:<br/>1. Standard Errors assume that the covariance matrix of the errors is correctly specified.



# 14장 오차의 자기상관

## 예제 14.1 지역별 사망률


```python
import pandas as pd
import statsmodels.formula.api as smf

Death = pd.read_csv('csv/loedata/Death.csv')
model = smf.ols('deathrate~drink+smoke+aged+vehipc+C(year)', data=Death) # C: categorical
model.fit().summary(slim=True) # ordinary
```

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>deathrate</td> <th>  R-squared:         </th> <td>   0.921</td> 
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.919</td> 
</tr>
<tr>
  <th>No. Observations:</th>  <td>   258</td>   <th>  F-statistic:       </th> <td>   487.3</td> 
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>3.42e-135</td>
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>       <td>   -0.2241</td> <td>    0.769</td> <td>   -0.291</td> <td> 0.771</td> <td>   -1.739</td> <td>    1.291</td>
</tr>
<tr>
  <th>C(year)[T.2009]</th> <td>   -0.3788</td> <td>    0.098</td> <td>   -3.867</td> <td> 0.000</td> <td>   -0.572</td> <td>   -0.186</td>
</tr>
<tr>
  <th>C(year)[T.2010]</th> <td>   -0.3510</td> <td>    0.102</td> <td>   -3.457</td> <td> 0.001</td> <td>   -0.551</td> <td>   -0.151</td>
</tr>
<tr>
  <th>drink</th>           <td>    0.0064</td> <td>    0.011</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.015</td> <td>    0.028</td>
</tr>
<tr>
  <th>smoke</th>           <td>    0.0333</td> <td>    0.018</td> <td>    1.873</td> <td> 0.062</td> <td>   -0.002</td> <td>    0.068</td>
</tr>
<tr>
  <th>aged</th>            <td>    0.4027</td> <td>    0.010</td> <td>   38.401</td> <td> 0.000</td> <td>    0.382</td> <td>    0.423</td>
</tr>
<tr>
  <th>vehipc</th>          <td>    1.4079</td> <td>    1.163</td> <td>    1.211</td> <td> 0.227</td> <td>   -0.882</td> <td>    3.698</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.91e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>



```python
model.fit(cov_type='HC3').summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>deathrate</td> <th>  R-squared:         </th> <td>   0.921</td> 
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.919</td> 
</tr>
<tr>
  <th>No. Observations:</th>  <td>   258</td>   <th>  F-statistic:       </th> <td>   650.1</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>HC3</td>    <th>  Prob (F-statistic):</th> <td>8.45e-150</td>
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>       <td>   -0.2241</td> <td>    0.785</td> <td>   -0.285</td> <td> 0.775</td> <td>   -1.763</td> <td>    1.315</td>
</tr>
<tr>
  <th>C(year)[T.2009]</th> <td>   -0.3788</td> <td>    0.095</td> <td>   -3.996</td> <td> 0.000</td> <td>   -0.565</td> <td>   -0.193</td>
</tr>
<tr>
  <th>C(year)[T.2010]</th> <td>   -0.3510</td> <td>    0.104</td> <td>   -3.371</td> <td> 0.001</td> <td>   -0.555</td> <td>   -0.147</td>
</tr>
<tr>
  <th>drink</th>           <td>    0.0064</td> <td>    0.011</td> <td>    0.565</td> <td> 0.572</td> <td>   -0.016</td> <td>    0.029</td>
</tr>
<tr>
  <th>smoke</th>           <td>    0.0333</td> <td>    0.019</td> <td>    1.770</td> <td> 0.077</td> <td>   -0.004</td> <td>    0.070</td>
</tr>
<tr>
  <th>aged</th>            <td>    0.4027</td> <td>    0.010</td> <td>   39.371</td> <td> 0.000</td> <td>    0.383</td> <td>    0.423</td>
</tr>
<tr>
  <th>vehipc</th>          <td>    1.4079</td> <td>    1.295</td> <td>    1.087</td> <td> 0.277</td> <td>   -1.130</td> <td>    3.946</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The condition number is large, 1.91e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>


## 예제 14.2 클러스터 개수에 따른 조정


```python
model.fit(cov_type='cluster', cov_kwds={'groups':Death.region}).summary(slim=True) # not for CC0 but for CC1
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>deathrate</td> <th>  R-squared:         </th> <td>   0.921</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.919</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   258</td>   <th>  F-statistic:       </th> <td>   493.2</td>
</tr>
<tr>
  <th>Covariance Type:</th>   <td>cluster</td>  <th>  Prob (F-statistic):</th> <td>8.24e-64</td>
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>       <td>   -0.2241</td> <td>    1.019</td> <td>   -0.220</td> <td> 0.826</td> <td>   -2.222</td> <td>    1.773</td>
</tr>
<tr>
  <th>C(year)[T.2009]</th> <td>   -0.3788</td> <td>    0.077</td> <td>   -4.948</td> <td> 0.000</td> <td>   -0.529</td> <td>   -0.229</td>
</tr>
<tr>
  <th>C(year)[T.2010]</th> <td>   -0.3510</td> <td>    0.099</td> <td>   -3.547</td> <td> 0.000</td> <td>   -0.545</td> <td>   -0.157</td>
</tr>
<tr>
  <th>drink</th>           <td>    0.0064</td> <td>    0.014</td> <td>    0.453</td> <td> 0.650</td> <td>   -0.021</td> <td>    0.034</td>
</tr>
<tr>
  <th>smoke</th>           <td>    0.0333</td> <td>    0.019</td> <td>    1.716</td> <td> 0.086</td> <td>   -0.005</td> <td>    0.071</td>
</tr>
<tr>
  <th>aged</th>            <td>    0.4027</td> <td>    0.014</td> <td>   29.775</td> <td> 0.000</td> <td>    0.376</td> <td>    0.429</td>
</tr>
<tr>
  <th>vehipc</th>          <td>    1.4079</td> <td>    1.725</td> <td>    0.816</td> <td> 0.414</td> <td>   -1.972</td> <td>    4.788</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors are robust to cluster correlation (cluster)<br/>[2] The condition number is large, 1.91e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>


## Durbin-Watson 검정

Durbin-Watson 검정 통계는 OLS 결과 테이블에 제시된다.


```python
import pandas as pd
import numpy as np

np.random.seed(101)
n = 100
x = 2*(np.arange(n) % 2)-1
y = 1+x+np.random.normal(size=n)
DF = pd.DataFrame({'x':x, 'y':y})
DF.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1</td>
      <td>2.706850</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2.628133</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
      <td>0.907969</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>2.503826</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1</td>
      <td>0.651118</td>
    </tr>
  </tbody>
</table>
</div>




```python
import statsmodels.formula.api as smf
ols = smf.ols('y~x', data=DF).fit()
ols.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.586</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.582</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   138.9</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 24 Jun 2024</td> <th>  Prob (F-statistic):</th> <td>1.72e-20</td>
</tr>
<tr>
  <th>Time:</th>                 <td>08:19:25</td>     <th>  Log-Likelihood:    </th> <td> -143.19</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   290.4</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   295.6</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    1.1664</td> <td>    0.102</td> <td>   11.397</td> <td> 0.000</td> <td>    0.963</td> <td>    1.369</td>
</tr>
<tr>
  <th>x</th>         <td>    1.2060</td> <td>    0.102</td> <td>   11.785</td> <td> 0.000</td> <td>    1.003</td> <td>    1.409</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.580</td> <th>  Durbin-Watson:     </th> <td>   2.008</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.748</td> <th>  Jarque-Bera (JB):  </th> <td>   0.565</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.176</td> <th>  Prob(JB):          </th> <td>   0.754</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.890</td> <th>  Cond. No.          </th> <td>    1.00</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


Durbin-Watson 검정통계값은 2.008이다. p값은 계산해 주지 않는다(R은 계산해 주고, python에서도 `dwtest` 패키지가 계산해 준다). 아마도 구식으로 DW 테이블을 참조하라는 것인가 보다.

## Breusch-Godfrey 검정

```python
# Continue
from statsmodels.stats.diagnostic import acorr_breusch_godfrey

acorr_breusch_godfrey(ols, nlags=1)[:4] # (lm, lmpval, fval, fpval)
```

    (0.28760257192601557,
     0.5917609704261441,
     0.2797791467901201,
     0.598054322774964)



# 16장 도구변수 추정

`statsmodels` 패키지의 경우 도구변수 추정이 복잡하고, `linearmodels` 패키지가 도구변수 추정에 간편한 인터페이스를 제공하나 `statsmodels`와의 통일성이 없다. 특히 `linearmodels`의 formula에서는 모형이 절편을 포함하면 반드시 `1`을 써 주어야 한다. 대부분의 모형에 절편이 포함되고 많은 사용자들이 절편에 관심을 갖지 않음을 고려하면 이는 상당히 비효율적이고 코딩 오류를 불러일으키는 접근방식이다. 또한 `linearmodels`의 default 표준오차는 이분산에 견고한 표준오차라는 점에도 주의하여야 한다.

인터페이스에 통일성이 없다는 것은 매우 불편하고 혼란을 야기한다. 공부할 목적이 아니면 도구변수 추정(또는 『계량경제학강의』의 다른 부분)에 파이썬(python)을 사용하는 것은 추천하지 않는다. (패키지 코드를 수정하는 것은 본 실습의 목적이 아니다.)

## OLS


```python
import pandas as pd
import statsmodels.formula.api as smf

Ivdata = pd.read_csv('csv/loedata/Ivdata.csv')
ols = smf.ols('y~x1+x2', data=Ivdata).fit()
ols.summary(slim=True)
```

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>y</td>     <th>  R-squared:         </th> <td>   0.708</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.702</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   100</td>   <th>  F-statistic:       </th> <td>   117.4</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>1.24e-26</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   -0.3650</td> <td>    0.820</td> <td>   -0.445</td> <td> 0.657</td> <td>   -1.992</td> <td>    1.262</td>
</tr>
<tr>
  <th>x1</th>        <td>    0.4831</td> <td>    0.057</td> <td>    8.458</td> <td> 0.000</td> <td>    0.370</td> <td>    0.597</td>
</tr>
<tr>
  <th>x2</th>        <td>    0.9448</td> <td>    0.064</td> <td>   14.677</td> <td> 0.000</td> <td>    0.817</td> <td>    1.073</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


## First-stage regression


```python
stage1 = smf.ols('x2~x1+z2a', data=Ivdata).fit()
stage1.summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>x2</td>     <th>  R-squared:         </th> <td>   0.295</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.281</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   100</td>   <th>  F-statistic:       </th> <td>   20.33</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>4.22e-08</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    6.3374</td> <td>    0.936</td> <td>    6.769</td> <td> 0.000</td> <td>    4.479</td> <td>    8.196</td>
</tr>
<tr>
  <th>x1</th>        <td>   -0.1319</td> <td>    0.079</td> <td>   -1.669</td> <td> 0.098</td> <td>   -0.289</td> <td>    0.025</td>
</tr>
<tr>
  <th>z2a</th>       <td>   21.8401</td> <td>    4.044</td> <td>    5.401</td> <td> 0.000</td> <td>   13.814</td> <td>   29.866</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


## Second-stage regression


```python
Ivdata['x2hat'] = stage1.fittedvalues
stage2 = smf.ols('y~x1+x2hat', data=Ivdata).fit()
stage2.summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>y</td>     <th>  R-squared:         </th> <td>   0.138</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.120</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   100</td>   <th>  F-statistic:       </th> <td>   7.748</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>0.000756</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    1.8827</td> <td>    2.250</td> <td>    0.837</td> <td> 0.405</td> <td>   -2.583</td> <td>    6.348</td>
</tr>
<tr>
  <th>x1</th>        <td>    0.4169</td> <td>    0.111</td> <td>    3.760</td> <td> 0.000</td> <td>    0.197</td> <td>    0.637</td>
</tr>
<tr>
  <th>x2hat</th>     <td>    0.6867</td> <td>    0.230</td> <td>    2.986</td> <td> 0.004</td> <td>    0.230</td> <td>    1.143</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


위 Second-stage regression에 보고되는 표준오차들에는 오류가 있다. 이를 보정해야 하는데, 완전수동 분산 추정이나 반자동 분산 추정은 건너뛰고 완전자동 도구변수 추정으로 넘어간다.

## 완전자동 도구변수 추정


```python
# pip install linearmodels
from linearmodels import IV2SLS

ivfm = 'y~1+x1+[x2~z2a]' # need constant (1) explicitly
ivmodel = IV2SLS.from_formula(ivfm, data=Ivdata)
tsls = ivmodel.fit(cov_type='unadjusted')
tsls
```




<table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>0.6592</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.6522</td> 
</tr>
<tr>
  <th>No. Observations:</th>        <td>100</td>       <th>  F-statistic:       </th> <td>40.418</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, Jun 24 2024</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>08:43:16</td>     <th>  Distribution:      </th> <td>chi2(2)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>      <td>unadjusted</td>    <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>  <td>1.8827</td>    <td>1.3932</td>   <td>1.3513</td> <td>0.1766</td>   <td>-0.8479</td>  <td>4.6132</td> 
</tr>
<tr>
  <th>x1</th>         <td>0.4169</td>    <td>0.0687</td>   <td>6.0725</td> <td>0.0000</td>   <td>0.2824</td>   <td>0.5515</td> 
</tr>
<tr>
  <th>x2</th>         <td>0.6867</td>    <td>0.1424</td>   <td>4.8229</td> <td>0.0000</td>   <td>0.4076</td>   <td>0.9657</td> 
</tr>
</table>
<div class="reg-notes">
Endogenous: x2<br/>Instruments: z2a<br/>Unadjusted Covariance (Homoskedastic)<br/>Debiased: False<br/>id: 0x12a633710
</div>


표준오차가 책과 약간 다른데, 오차분산을 추정할 때 $n-k-1$이 아니라 $n$으로 나누었기 때문이다. $n-k-1$로 나누는 옵션은 보이지 않는다(`help(IV2SLS.fit)` 참고). HC0 유형 표준오차는 다음과 같이 구한다.


```python
tslsh = ivmodel.fit(cov_type='robust')
tslsh
```




<table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>0.6592</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.6522</td> 
</tr>
<tr>
  <th>No. Observations:</th>        <td>100</td>       <th>  F-statistic:       </th> <td>31.850</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, Jun 24 2024</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>08:43:16</td>     <th>  Distribution:      </th> <td>chi2(2)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>  <td>1.8827</td>    <td>1.5194</td>   <td>1.2391</td> <td>0.2153</td>   <td>-1.0954</td>  <td>4.8607</td> 
</tr>
<tr>
  <th>x1</th>         <td>0.4169</td>    <td>0.0815</td>   <td>5.1142</td> <td>0.0000</td>   <td>0.2571</td>   <td>0.5767</td> 
</tr>
<tr>
  <th>x2</th>         <td>0.6867</td>    <td>0.1299</td>   <td>5.2860</td> <td>0.0000</td>   <td>0.4321</td>   <td>0.9413</td> 
</tr>
</table>
<div class="reg-notes">
Endogenous: x2<br/>Instruments: z2a<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False<br/>id: 0x12a69c8f0
</div>


## First-stage test


```python
smf.ols('x2~x1+z2a', data=Ivdata).fit().summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>x2</td>     <th>  R-squared:         </th> <td>   0.295</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.281</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   100</td>   <th>  F-statistic:       </th> <td>   20.33</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>4.22e-08</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    6.3374</td> <td>    0.936</td> <td>    6.769</td> <td> 0.000</td> <td>    4.479</td> <td>    8.196</td>
</tr>
<tr>
  <th>x1</th>        <td>   -0.1319</td> <td>    0.079</td> <td>   -1.669</td> <td> 0.098</td> <td>   -0.289</td> <td>    0.025</td>
</tr>
<tr>
  <th>z2a</th>       <td>   21.8401</td> <td>    4.044</td> <td>    5.401</td> <td> 0.000</td> <td>   13.814</td> <td>   29.866</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>



```python
smf.ols('x2~x1+z2a', data=Ivdata).fit(cov_type="HC3").summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>      <td>x2</td>   <th>  R-squared:         </th> <td>   0.295</td>
</tr>
<tr>
  <th>Model:</th>              <td>OLS</td>  <th>  Adj. R-squared:    </th> <td>   0.281</td>
</tr>
<tr>
  <th>No. Observations:</th> <td>   100</td> <th>  F-statistic:       </th> <td>   17.75</td>
</tr>
<tr>
  <th>Covariance Type:</th>    <td>HC3</td>  <th>  Prob (F-statistic):</th> <td>2.69e-07</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    6.3374</td> <td>    1.061</td> <td>    5.972</td> <td> 0.000</td> <td>    4.258</td> <td>    8.417</td>
</tr>
<tr>
  <th>x1</th>        <td>   -0.1319</td> <td>    0.088</td> <td>   -1.491</td> <td> 0.136</td> <td>   -0.305</td> <td>    0.042</td>
</tr>
<tr>
  <th>z2a</th>       <td>   21.8401</td> <td>    4.389</td> <td>    4.976</td> <td> 0.000</td> <td>   13.238</td> <td>   30.442</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)
</div>



```python
stage1a = smf.ols('x2~x1+z2a+z2b', data=Ivdata).fit()
stage1a.f_test('z2a=0,z2b=0')
```




    <class 'statsmodels.stats.contrast.ContrastResults'>
    <F test: F=14.539152594855231, p=3.049887117946441e-06, df_denom=96, df_num=2>



## 설명변수 외생성의 검정


```python
Ivdata['v2hat'] = stage1.resid
smf.ols('y~x1+x2+v2hat', data=Ivdata).fit().summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>y</td>     <th>  R-squared:         </th> <td>   0.722</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.714</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   100</td>   <th>  F-statistic:       </th> <td>   83.21</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>1.33e-26</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    1.8827</td> <td>    1.284</td> <td>    1.467</td> <td> 0.146</td> <td>   -0.665</td> <td>    4.431</td>
</tr>
<tr>
  <th>x1</th>        <td>    0.4169</td> <td>    0.063</td> <td>    6.591</td> <td> 0.000</td> <td>    0.291</td> <td>    0.543</td>
</tr>
<tr>
  <th>x2</th>        <td>    0.6867</td> <td>    0.131</td> <td>    5.234</td> <td> 0.000</td> <td>    0.426</td> <td>    0.947</td>
</tr>
<tr>
  <th>v2hat</th>     <td>    0.3358</td> <td>    0.150</td> <td>    2.245</td> <td> 0.027</td> <td>    0.039</td> <td>    0.633</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


## 도구변수 외생성의 검정


```python
tsls = IV2SLS.from_formula('y~1+x1+[x2~z2a+z2b]', data=Ivdata).fit(cov_type='unadjusted') # see above for ivmodel
tsls.sargan
```




    Sargan's test of overidentification
    H0: The model is not overidentified.
    Statistic: 0.3355
    P-value: 0.5624
    Distributed: chi2(1)
    WaldTestStatistic, id: 0x12a657f50



linearmodels를 사용하려면 회귀식에 상수항(1)을 명시적으로 표시해 주어야 함에 유의하여야 한다.

## 예제: 교육수익률


```python
import pandas as pd
import statsmodels.formula.api as smf

Schooling = pd.read_csv('csv/Ecdat/Schooling.csv')

fm = 'lwage76~ed76+exp76+smsa76'
```

### OLS 추정


```python
ols = smf.ols(fm, data=Schooling).fit()
ols.summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>     <td>lwage76</td>  <th>  R-squared:         </th> <td>   0.215</td> 
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.214</td> 
</tr>
<tr>
  <th>No. Observations:</th>  <td>  3010</td>   <th>  F-statistic:       </th> <td>   274.7</td> 
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>1.43e-157</td>
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    4.6020</td> <td>    0.063</td> <td>   73.373</td> <td> 0.000</td> <td>    4.479</td> <td>    4.725</td>
</tr>
<tr>
  <th>smsa76[T.yes]</th> <td>    0.1837</td> <td>    0.016</td> <td>   11.386</td> <td> 0.000</td> <td>    0.152</td> <td>    0.215</td>
</tr>
<tr>
  <th>ed76</th>          <td>    0.0878</td> <td>    0.004</td> <td>   24.610</td> <td> 0.000</td> <td>    0.081</td> <td>    0.095</td>
</tr>
<tr>
  <th>exp76</th>         <td>    0.0411</td> <td>    0.002</td> <td>   17.985</td> <td> 0.000</td> <td>    0.037</td> <td>    0.046</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


### IQ를 대리변수로 사용


```python
fm_iq = fm + '+iqscore'
smf.ols(fm_iq, data=Schooling).fit().summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>     <td>lwage76</td>  <th>  R-squared:         </th> <td>   0.192</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.190</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>  2061</td>   <th>  F-statistic:       </th> <td>   122.0</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>1.70e-93</td>
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    4.4761</td> <td>    0.089</td> <td>   50.331</td> <td> 0.000</td> <td>    4.302</td> <td>    4.650</td>
</tr>
<tr>
  <th>smsa76[T.yes]</th> <td>    0.1548</td> <td>    0.019</td> <td>    8.145</td> <td> 0.000</td> <td>    0.118</td> <td>    0.192</td>
</tr>
<tr>
  <th>ed76</th>          <td>    0.0657</td> <td>    0.005</td> <td>   13.286</td> <td> 0.000</td> <td>    0.056</td> <td>    0.075</td>
</tr>
<tr>
  <th>exp76</th>         <td>    0.0451</td> <td>    0.003</td> <td>   16.288</td> <td> 0.000</td> <td>    0.040</td> <td>    0.051</td>
</tr>
<tr>
  <th>iqscore</th>       <td>    0.0044</td> <td>    0.001</td> <td>    6.972</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.13e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>


### First-stage regression


```python
fm_stage1 = 'ed76~exp76+smsa76+momed'
fm_stage1
```




    'ed76~exp76+smsa76+momed'




```python
stage1 = smf.ols(fm_stage1, data=Schooling).fit()
stage1.summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>      <td>ed76</td>    <th>  R-squared:         </th> <td>   0.488</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.487</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>  3010</td>   <th>  F-statistic:       </th> <td>   953.2</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> 
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>   13.9863</td> <td>    0.179</td> <td>   78.008</td> <td> 0.000</td> <td>   13.635</td> <td>   14.338</td>
</tr>
<tr>
  <th>smsa76[T.yes]</th> <td>    0.4783</td> <td>    0.078</td> <td>    6.110</td> <td> 0.000</td> <td>    0.325</td> <td>    0.632</td>
</tr>
<tr>
  <th>exp76</th>         <td>   -0.3690</td> <td>    0.009</td> <td>  -41.498</td> <td> 0.000</td> <td>   -0.386</td> <td>   -0.352</td>
</tr>
<tr>
  <th>momed</th>         <td>    0.2132</td> <td>    0.012</td> <td>   17.327</td> <td> 0.000</td> <td>    0.189</td> <td>    0.237</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


### Two stage least squares


```python
from linearmodels import IV2SLS

iv_model = IV2SLS.from_formula('lwage76~1+[ed76~momed]+exp76+smsa76', data=Schooling) # 1+!!!
tsls = iv_model.fit(cov_type='unadjusted')
tsls
```




<table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>         <td>lwage76</td>     <th>  R-squared:         </th> <td>0.1499</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.1490</td> 
</tr>
<tr>
  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>339.12</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, Jun 24 2024</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>08:43:17</td>     <th>  Distribution:      </th> <td>chi2(3)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>      <td>unadjusted</td>    <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
        <td></td>        <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>      <td>3.6712</td>    <td>0.2044</td>   <td>17.960</td> <td>0.0000</td>   <td>3.2705</td>   <td>4.0718</td> 
</tr>
<tr>
  <th>exp76</th>          <td>0.0644</td>    <td>0.0054</td>   <td>11.925</td> <td>0.0000</td>   <td>0.0538</td>   <td>0.0750</td> 
</tr>
<tr>
  <th>smsa76[T.yes]</th>  <td>0.1501</td>    <td>0.0182</td>   <td>8.2525</td> <td>0.0000</td>   <td>0.1144</td>   <td>0.1857</td> 
</tr>
<tr>
  <th>ed76</th>           <td>0.1442</td>    <td>0.0123</td>   <td>11.712</td> <td>0.0000</td>   <td>0.1201</td>   <td>0.1684</td> 
</tr>
</table>
<div class="reg-notes">
Endogenous: ed76<br/>Instruments: momed<br/>Unadjusted Covariance (Homoskedastic)<br/>Debiased: False<br/>id: 0x12a69cd70
</div>



```python
tsls_h = iv_model.fit(cov_type='robust')
tsls_h
```




<table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>         <td>lwage76</td>     <th>  R-squared:         </th> <td>0.1499</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.1490</td> 
</tr>
<tr>
  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>357.82</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, Jun 24 2024</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>08:43:17</td>     <th>  Distribution:      </th> <td>chi2(3)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
        <td></td>        <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>      <td>3.6712</td>    <td>0.2023</td>   <td>18.144</td> <td>0.0000</td>   <td>3.2746</td>   <td>4.0677</td> 
</tr>
<tr>
  <th>exp76</th>          <td>0.0644</td>    <td>0.0053</td>   <td>12.056</td> <td>0.0000</td>   <td>0.0540</td>   <td>0.0749</td> 
</tr>
<tr>
  <th>smsa76[T.yes]</th>  <td>0.1501</td>    <td>0.0180</td>   <td>8.3391</td> <td>0.0000</td>   <td>0.1148</td>   <td>0.1854</td> 
</tr>
<tr>
  <th>ed76</th>           <td>0.1442</td>    <td>0.0122</td>   <td>11.778</td> <td>0.0000</td>   <td>0.1202</td>   <td>0.1682</td> 
</tr>
</table>
<div class="reg-notes">
Endogenous: ed76<br/>Instruments: momed<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False<br/>id: 0x12b0352b0
</div>


### Endogeneity test


```python
stage1 = smf.ols(fm_stage1, data=Schooling).fit()
Schooling['vhat'] = stage1.resid
aux = smf.ols(fm + '+vhat', data=Schooling).fit()
aux.summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>     <td>lwage76</td>  <th>  R-squared:         </th> <td>   0.222</td> 
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.221</td> 
</tr>
<tr>
  <th>No. Observations:</th>  <td>  3010</td>   <th>  F-statistic:       </th> <td>   214.0</td> 
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>9.56e-162</td>
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    3.6712</td> <td>    0.196</td> <td>   18.754</td> <td> 0.000</td> <td>    3.287</td> <td>    4.055</td>
</tr>
<tr>
  <th>smsa76[T.yes]</th> <td>    0.1501</td> <td>    0.017</td> <td>    8.618</td> <td> 0.000</td> <td>    0.116</td> <td>    0.184</td>
</tr>
<tr>
  <th>ed76</th>          <td>    0.1442</td> <td>    0.012</td> <td>   12.230</td> <td> 0.000</td> <td>    0.121</td> <td>    0.167</td>
</tr>
<tr>
  <th>exp76</th>         <td>    0.0644</td> <td>    0.005</td> <td>   12.452</td> <td> 0.000</td> <td>    0.054</td> <td>    0.075</td>
</tr>
<tr>
  <th>vhat</th>          <td>   -0.0621</td> <td>    0.012</td> <td>   -5.017</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.038</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>



```python
smf.ols(fm + '+vhat', data=Schooling).fit(cov_type='HC3').summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>lwage76</td> <th>  R-squared:         </th> <td>   0.222</td> 
</tr>
<tr>
  <th>Model:</th>              <td>OLS</td>   <th>  Adj. R-squared:    </th> <td>   0.221</td> 
</tr>
<tr>
  <th>No. Observations:</th> <td>  3010</td>  <th>  F-statistic:       </th> <td>   217.3</td> 
</tr>
<tr>
  <th>Covariance Type:</th>    <td>HC3</td>   <th>  Prob (F-statistic):</th> <td>5.44e-164</td>
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    3.6712</td> <td>    0.196</td> <td>   18.732</td> <td> 0.000</td> <td>    3.287</td> <td>    4.055</td>
</tr>
<tr>
  <th>smsa76[T.yes]</th> <td>    0.1501</td> <td>    0.017</td> <td>    8.717</td> <td> 0.000</td> <td>    0.116</td> <td>    0.184</td>
</tr>
<tr>
  <th>ed76</th>          <td>    0.1442</td> <td>    0.012</td> <td>   12.161</td> <td> 0.000</td> <td>    0.121</td> <td>    0.167</td>
</tr>
<tr>
  <th>exp76</th>         <td>    0.0644</td> <td>    0.005</td> <td>   12.399</td> <td> 0.000</td> <td>    0.054</td> <td>    0.075</td>
</tr>
<tr>
  <th>vhat</th>          <td>   -0.0621</td> <td>    0.013</td> <td>   -4.888</td> <td> 0.000</td> <td>   -0.087</td> <td>   -0.037</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)
</div>


### Overidentification test


```python
# Don't miss out 1 below
tsls2 = IV2SLS.from_formula('lwage76~1+[ed76~momed+daded]+exp76+smsa76', data=Schooling).fit()
tsls2.sargan
```




    Sargan's test of overidentification
    H0: The model is not overidentified.
    Statistic: 3.2653
    P-value: 0.0708
    Distributed: chi2(1)
    WaldTestStatistic, id: 0x12b0b9490



### Robust overidentification test


```python
# first stage regression
stage1 = smf.ols('ed76~momed+daded+exp76+smsa76', data=Schooling).fit()
Schooling['ed76hat'] = stage1.fittedvalues
# orthogonalized overidentifying instruments
w1 = IV2SLS.from_formula('daded~1+[ed76hat~ed76]+exp76+smsa76', data=Schooling).fit().resids
# multiply w1 to 2SLS residuals
u = IV2SLS.from_formula('lwage76~1+[ed76~momed+daded]+exp76+smsa76', data=Schooling).fit().resids
Schooling['w1u'] = w1*u
# get the n*R2 stat
Schooling['one'] = [1]*len(Schooling)
aux = smf.ols('one~w1u-1', data=Schooling).fit()
stat = aux.nobs*aux.rsquared
stat
```




    3.185349075973105




```python
# p-value
from scipy.stats import chi2

1-chi2.cdf(stat,1)
```




    0.07430112606532835



## 제곱항

### 도구변수 제곱항을 도구변수로 사용


```python
import pandas as pd

Ivdata = pd.read_csv('csv/loedata/Ivdata.csv')
# Require 1!
ivreg = IV2SLS.from_formula('y~1+x1+[x2+I(x2**2)~z2a+I(z2a**2)]', data=Ivdata).fit(cov_type='unadjusted')
ivreg
```




<table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>0.6619</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.6514</td> 
</tr>
<tr>
  <th>No. Observations:</th>        <td>100</td>       <th>  F-statistic:       </th> <td>40.760</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, Jun 24 2024</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>08:43:17</td>     <th>  Distribution:      </th> <td>chi2(3)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>      <td>unadjusted</td>    <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
       <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>   <td>1.9795</td>    <td>1.5627</td>   <td>1.2668</td> <td>0.2052</td>   <td>-1.0833</td>  <td>5.0423</td> 
</tr>
<tr>
  <th>x1</th>          <td>0.4188</td>    <td>0.0705</td>   <td>5.9396</td> <td>0.0000</td>   <td>0.2806</td>   <td>0.5571</td> 
</tr>
<tr>
  <th>x2</th>          <td>0.6159</td>    <td>0.5829</td>   <td>1.0567</td> <td>0.2907</td>   <td>-0.5265</td>  <td>1.7583</td> 
</tr>
<tr>
  <th>I(x2 ** 2)</th>  <td>0.0066</td>    <td>0.0536</td>   <td>0.1236</td> <td>0.9017</td>   <td>-0.0985</td>  <td>0.1118</td> 
</tr>
</table>
<div class="reg-notes">
Endogenous: x2, I(x2 ** 2)<br/>Instruments: z2a, I(z2a ** 2)<br/>Unadjusted Covariance (Homoskedastic)<br/>Debiased: False<br/>id: 0x12b0d6a20
</div>


### 통제함수


```python
Ivdata['v2hat'] = smf.ols('x2~x1+z2a+z2b', data=Ivdata).fit().resid
smf.ols('y~x1+x2+I(x2**2)+v2hat', data=Ivdata).fit().summary(slim=True)
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>y</td>     <th>  R-squared:         </th> <td>   0.723</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.712</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   100</td>   <th>  F-statistic:       </th> <td>   62.06</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>1.12e-25</td>
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>  <td>    1.9932</td> <td>    1.305</td> <td>    1.528</td> <td> 0.130</td> <td>   -0.597</td> <td>    4.583</td>
</tr>
<tr>
  <th>x1</th>         <td>    0.4217</td> <td>    0.064</td> <td>    6.632</td> <td> 0.000</td> <td>    0.295</td> <td>    0.548</td>
</tr>
<tr>
  <th>x2</th>         <td>    0.5732</td> <td>    0.210</td> <td>    2.734</td> <td> 0.007</td> <td>    0.157</td> <td>    0.989</td>
</tr>
<tr>
  <th>I(x2 ** 2)</th> <td>    0.0112</td> <td>    0.015</td> <td>    0.731</td> <td> 0.467</td> <td>   -0.019</td> <td>    0.042</td>
</tr>
<tr>
  <th>v2hat</th>      <td>    0.3219</td> <td>    0.150</td> <td>    2.145</td> <td> 0.035</td> <td>    0.024</td> <td>    0.620</td>
</tr>
</table>
<div class="reg-notes">
Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>


위의 표준오차들은 (`v2hat`의 계수가 0인 경우, 즉 설명변수가 외생적인 경우, 즉 도구변수 추정이 불필요한 경우를 제외하면) 잘못되어 있음에 유의하라.
